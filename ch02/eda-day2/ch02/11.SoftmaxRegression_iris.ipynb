{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy AI 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iris():\n",
    "    iris = np.loadtxt('./iris.csv', delimiter=',', dtype=np.float32)\n",
    "    print(iris)\n",
    "    print(iris.shape, iris.dtype)  # (150, 7) float64 --> float32로 변환\n",
    "\n",
    "    np.random.shuffle(iris)\n",
    "\n",
    "    x = iris[:, :4]\n",
    "    y = iris[:, 4:]  # 1, 0, 0  One-hot vector\n",
    "    print(x.shape, y.shape)  # (150, 4) (150, 3)\n",
    "\n",
    "    train_size = int(len(x) * 0.7)\n",
    "    x_train, x_test = x[:train_size], x[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    print(x_train.shape, x_test.shape)  # (105, 4) (45, 4)\n",
    "    print(y_train.shape, y_test.shape)  # (105, 3) (45, 3)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_regression_iris():\n",
    "    x_train, y_train, x_test, y_test = get_iris()\n",
    "\n",
    "    #w = tf.Variable(tf.random_normal([4, 3])) # 4:x_train.shape[1], 3:y_train.shape[1]\n",
    "    #b = tf.Variable(tf.random_normal([3])) # 3:y_train.shape[1]\n",
    "    w = tf.Variable(tf.random_normal([x_train.shape[1], y_train.shape[1]])) # 4:x_train.shape[1], 3:y_train.shape[1]\n",
    "    b = tf.Variable(tf.random_normal([y_train.shape[1]])) # 3:y_train.shape[1]\n",
    "\n",
    "    ph_x = tf.placeholder(tf.float32)  # (105, 4) (x_train.shape[0], x_train.shape[1])\n",
    "    \n",
    "    #(105, 3) = (x_train.shape[0], x_train.shape[1]) @ (x_train.shape[1], y_train.shape[1])\n",
    "    #(105, 3) = (105, 4) @ (4, 3)\n",
    "    z = ph_x @ w + b\n",
    "    hx = tf.nn.softmax(z)\n",
    "\n",
    "    loss_i = tf.nn.softmax_cross_entropy_with_logits_v2(logits=z,\n",
    "                                                        labels=y_train)\n",
    "    loss = tf.reduce_mean(loss_i)\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(1000):\n",
    "        sess.run(train, {ph_x: x_train})\n",
    "        if i%10 == 0: print(i, sess.run(loss, {ph_x: x_train}))\n",
    "    print('-' * 50)\n",
    "\n",
    "    preds = sess.run(hx, {ph_x: x_test})\n",
    "    # print(preds)\n",
    "    pred_arg = np.argmax(preds, axis=1)\n",
    "    print(pred_arg)\n",
    "\n",
    "    y_arg = np.argmax(y_test, axis=1)\n",
    "    print(y_arg)\n",
    "\n",
    "    print('acc:', np.mean(pred_arg == y_arg))\n",
    "\n",
    "#     types = np.array(['Setosa', 'Versicolor', 'Virginica'])\n",
    "#     print(types[pred_arg])\n",
    "#     print('-'*50)\n",
    "\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 ... 1.  0.  0. ]\n",
      " [4.9 3.  1.4 ... 1.  0.  0. ]\n",
      " [4.7 3.2 1.3 ... 1.  0.  0. ]\n",
      " ...\n",
      " [6.5 3.  5.2 ... 0.  0.  1. ]\n",
      " [6.2 3.4 5.4 ... 0.  0.  1. ]\n",
      " [5.9 3.  5.1 ... 0.  0.  1. ]]\n",
      "(150, 7) float32\n",
      "(150, 4) (150, 3)\n",
      "(105, 4) (45, 4)\n",
      "(105, 3) (45, 3)\n",
      "0 1.4858042\n",
      "10 0.7374481\n",
      "20 0.74302214\n",
      "30 0.70673305\n",
      "40 0.6756183\n",
      "50 0.6472952\n",
      "60 0.6206346\n",
      "70 0.59501785\n",
      "80 0.5700669\n",
      "90 0.5455288\n",
      "100 0.5212245\n",
      "110 0.49702823\n",
      "120 0.47285655\n",
      "130 0.44866866\n",
      "140 0.4244718\n",
      "150 0.40033445\n",
      "160 0.3764046\n",
      "170 0.35294554\n",
      "180 0.3303894\n",
      "190 0.3094147\n",
      "200 0.29099813\n",
      "210 0.2762469\n",
      "220 0.26574165\n",
      "230 0.2587612\n",
      "240 0.25370654\n",
      "250 0.24939148\n",
      "260 0.24538162\n",
      "270 0.24158047\n",
      "280 0.23796399\n",
      "290 0.2345178\n",
      "300 0.2312294\n",
      "310 0.2280877\n",
      "320 0.22508265\n",
      "330 0.22220519\n",
      "340 0.21944702\n",
      "350 0.21680062\n",
      "360 0.21425909\n",
      "370 0.21181607\n",
      "380 0.20946585\n",
      "390 0.20720299\n",
      "400 0.20502248\n",
      "410 0.20291989\n",
      "420 0.20089088\n",
      "430 0.19893157\n",
      "440 0.1970383\n",
      "450 0.19520763\n",
      "460 0.19343649\n",
      "470 0.19172186\n",
      "480 0.19006093\n",
      "490 0.18845122\n",
      "500 0.1868902\n",
      "510 0.18537572\n",
      "520 0.18390554\n",
      "530 0.18247777\n",
      "540 0.18109043\n",
      "550 0.17974183\n",
      "560 0.17843026\n",
      "570 0.17715421\n",
      "580 0.17591211\n",
      "590 0.1747026\n",
      "600 0.17352435\n",
      "610 0.17237613\n",
      "620 0.17125675\n",
      "630 0.17016505\n",
      "640 0.16910003\n",
      "650 0.16806063\n",
      "660 0.16704589\n",
      "670 0.16605487\n",
      "680 0.16508682\n",
      "690 0.1641408\n",
      "700 0.16321608\n",
      "710 0.16231191\n",
      "720 0.16142756\n",
      "730 0.16056235\n",
      "740 0.15971565\n",
      "750 0.15888686\n",
      "760 0.1580753\n",
      "770 0.15728049\n",
      "780 0.1565019\n",
      "790 0.15573896\n",
      "800 0.15499115\n",
      "810 0.15425806\n",
      "820 0.15353924\n",
      "830 0.15283424\n",
      "840 0.15214258\n",
      "850 0.15146397\n",
      "860 0.15079792\n",
      "870 0.15014414\n",
      "880 0.14950223\n",
      "890 0.1488719\n",
      "900 0.14825279\n",
      "910 0.14764453\n",
      "920 0.1470469\n",
      "930 0.14645955\n",
      "940 0.14588225\n",
      "950 0.1453147\n",
      "960 0.14475669\n",
      "970 0.14420785\n",
      "980 0.14366807\n",
      "990 0.14313701\n",
      "--------------------------------------------------\n",
      "[0 1 1 0 2 0 1 0 0 0 2 0 2 1 1 0 1 2 0 0 1 2 1 0 0 1 1 0 0 2 2 2 2 0 0 0 2\n",
      " 2 0 1 0 2 1 0 1]\n",
      "[0 1 1 0 2 0 1 0 0 0 2 0 2 1 1 0 1 2 0 0 1 2 1 0 0 1 1 0 0 2 2 2 2 0 0 0 2\n",
      " 2 0 1 0 2 1 0 1]\n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "softmax_regression_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
